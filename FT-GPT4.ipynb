{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, PyPDFDirectoryLoader, PyPDFLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import openai\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import shutil\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"PatronusAI/financebench\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_KEY = os.getenv('OPENAI_KEY')\n",
    "openai.api_key = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>financebench_id</th>\n",
       "      <th>doc_name</th>\n",
       "      <th>doc_link</th>\n",
       "      <th>doc_period</th>\n",
       "      <th>question_type</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>evidence_text</th>\n",
       "      <th>page_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>financebench_id_03029</td>\n",
       "      <td>3M_2018_10K</td>\n",
       "      <td>https://investors.3m.com/financials/sec-filing...</td>\n",
       "      <td>2018</td>\n",
       "      <td>metrics-generated</td>\n",
       "      <td>What is the FY2018 capital expenditure amount ...</td>\n",
       "      <td>$1577.00</td>\n",
       "      <td>Table of Contents \\n3M Company and Subsidiarie...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>financebench_id_04672</td>\n",
       "      <td>3M_2018_10K</td>\n",
       "      <td>https://investors.3m.com/financials/sec-filing...</td>\n",
       "      <td>2018</td>\n",
       "      <td>metrics-generated</td>\n",
       "      <td>Assume that you are a public equities analyst....</td>\n",
       "      <td>$8.70</td>\n",
       "      <td>Table of Contents \\n3M Company and Subsidiarie...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         financebench_id     doc_name  \\\n",
       "0  financebench_id_03029  3M_2018_10K   \n",
       "1  financebench_id_04672  3M_2018_10K   \n",
       "\n",
       "                                            doc_link  doc_period  \\\n",
       "0  https://investors.3m.com/financials/sec-filing...        2018   \n",
       "1  https://investors.3m.com/financials/sec-filing...        2018   \n",
       "\n",
       "       question_type                                           question  \\\n",
       "0  metrics-generated  What is the FY2018 capital expenditure amount ...   \n",
       "1  metrics-generated  Assume that you are a public equities analyst....   \n",
       "\n",
       "     answer                                      evidence_text page_number  \n",
       "0  $1577.00  Table of Contents \\n3M Company and Subsidiarie...          60  \n",
       "1     $8.70  Table of Contents \\n3M Company and Subsidiarie...          58  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_openai_json(data,filename):\n",
    "    \"\"\"\n",
    "    Converts a given dataset into a JSON Lines (JSONL) file suitable for OpenAI's GPT-3.5 turbo model.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame or similar data structure): Input data containing text and labels.\n",
    "\n",
    "    The function processes the input data row by row, constructing conversations for each row with a system message, user message, and an assistant message. It then writes the generated conversation data to a JSONL file.\n",
    " \n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store conversation data\n",
    "    message_list = []\n",
    "\n",
    "    # Iterate through the rows in the input data\n",
    "    for _, row in data.iterrows():\n",
    "        # Create a system message as an initial instruction\n",
    "        system_message = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\":  f\"You are a factual chatbot that answers questions about 10-K documents. You only answer with answers you find in the text, no outside information. Here is the question {row['question']}.\" \n",
    "        }\n",
    "\n",
    "        # Append the system message to the conversation\n",
    "        message_list.append({\"messages\": [system_message]})\n",
    "\n",
    "        # Create a user message based on the 'text' column from the data\n",
    "        user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": row['evidence_text']\n",
    "        }\n",
    "\n",
    "        # Append the user message to the conversation\n",
    "        message_list[-1][\"messages\"].append(user_message)\n",
    "\n",
    "        # Create an assistant message based on the 'coarse_label' column from the data\n",
    "        assistant_message = {\n",
    "            \"role\": 'assistant',\n",
    "            \"content\": row['answer']\n",
    "        }\n",
    "\n",
    "        # Append the assistant message to the conversation\n",
    "        message_list[-1][\"messages\"].append(assistant_message)\n",
    "\n",
    "    # Write the conversation data to a JSON Lines (JSONL) file\n",
    "    with open(filename, \"w\") as json_file:\n",
    "        for message in message_list:\n",
    "            # Serialize the conversation data to JSON and write it to the file\n",
    "            json.dump(message, json_file)\n",
    "            json_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>financebench_id</th>\n",
       "      <th>doc_name</th>\n",
       "      <th>doc_link</th>\n",
       "      <th>doc_period</th>\n",
       "      <th>question_type</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>evidence_text</th>\n",
       "      <th>page_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>financebench_id_03029</td>\n",
       "      <td>3M_2018_10K</td>\n",
       "      <td>https://investors.3m.com/financials/sec-filing...</td>\n",
       "      <td>2018</td>\n",
       "      <td>metrics-generated</td>\n",
       "      <td>What is the FY2018 capital expenditure amount ...</td>\n",
       "      <td>$1577.00</td>\n",
       "      <td>Table of Contents \\n3M Company and Subsidiarie...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>financebench_id_04672</td>\n",
       "      <td>3M_2018_10K</td>\n",
       "      <td>https://investors.3m.com/financials/sec-filing...</td>\n",
       "      <td>2018</td>\n",
       "      <td>metrics-generated</td>\n",
       "      <td>Assume that you are a public equities analyst....</td>\n",
       "      <td>$8.70</td>\n",
       "      <td>Table of Contents \\n3M Company and Subsidiarie...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         financebench_id     doc_name  \\\n",
       "0  financebench_id_03029  3M_2018_10K   \n",
       "1  financebench_id_04672  3M_2018_10K   \n",
       "\n",
       "                                            doc_link  doc_period  \\\n",
       "0  https://investors.3m.com/financials/sec-filing...        2018   \n",
       "1  https://investors.3m.com/financials/sec-filing...        2018   \n",
       "\n",
       "       question_type                                           question  \\\n",
       "0  metrics-generated  What is the FY2018 capital expenditure amount ...   \n",
       "1  metrics-generated  Assume that you are a public equities analyst....   \n",
       "\n",
       "     answer                                      evidence_text page_number  \n",
       "0  $1577.00  Table of Contents \\n3M Company and Subsidiarie...          60  \n",
       "1     $8.70  Table of Contents \\n3M Company and Subsidiarie...          58  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(model_id,num_label,pandas_df):\n",
    "    df = pandas_df.iloc[:num_label]\n",
    "    filename = f'ft_increment_{num_label}.jsonl'\n",
    "    text_to_openai_json(df, filename)\n",
    "    loader = openai.File.create(file=open(filename, \"rb\"), purpose='fine-tune')\n",
    "    fine_tuning_job = openai.FineTuningJob.create(training_file=loader.id, model=\"gpt-3.5-turbo-1106\")\n",
    "    return fine_tuning_job.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_fine_tuning(job_id):\n",
    "    while True:\n",
    "        response = openai.FineTuningJob.retrieve(job_id)\n",
    "        print(response[\"fine_tuned_model\"])\n",
    "        if response[\"fine_tuned_model\"]:\n",
    "            print(response[\"fine_tuned_model\"])\n",
    "            return response[\"fine_tuned_model\"]\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"You are a factual chatbot that answers questions about 10-K documents. You only answer with answers you find in the text, no outside information.\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      What is the FY2018 capital expenditure amount ...\n",
       "1      Assume that you are a public equities analyst....\n",
       "2      Is 3M a capital-intensive business based on FY...\n",
       "3      What drove operating margin change as of FY202...\n",
       "4      If we exclude the impact of M&A, which segment...\n",
       "                             ...                        \n",
       "145    Is Verizon a capital intensive business based ...\n",
       "146    Has Verizon increased its debt on balance shee...\n",
       "147    What is FY2018 days payable outstanding (DPO) ...\n",
       "148    Based on the information provided primarily in...\n",
       "149    What is the FY2018 - FY2020 3 year average una...\n",
       "Name: question, Length: 150, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_10K_responses(data,model_id):\n",
    "    syntheses = []\n",
    "    system_content = \"You are a factual chatbot that answers questions about 10-K documents. You only answer with answers you find in the text, no outside information. Here the question\" \n",
    "    for idx, row in data.iterrows():\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model= model_id ,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_content + data['question']},\n",
    "                {\"role\": \"user\", \"content\": row['evidence_text'] }\n",
    "            ])\n",
    "        \n",
    "        #print(f'text: {row}')\n",
    "        print(completion.choices[0].message.content)\n",
    "        syntheses.append(completion.choices[0].message.content)\n",
    "    syntheses_df = pd.DataFrame({'evidence_text': row['evidence_text'], 'answer' : row['answer'], 'syntheses' : syntheses })\n",
    "    \n",
    "    return syntheses_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine_Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compare_strings(text1, text2):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([text1, text2])\n",
    "    # Calculate the cosine similarity between the vectors\n",
    "    similarity = cosine_similarity(vectors)\n",
    "    return similarity[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cosine_sim(response_df):\n",
    "    list_of_cosine_similarity = []\n",
    "\n",
    "    for index, row in response_df.iterrows():\n",
    "                \n",
    "        model_response = row['syntheses']\n",
    "        answer = row['answer']\n",
    "\n",
    "        sim = compare_strings(answer, model_response)\n",
    "\n",
    "        #add the similarity to the list\n",
    "        list_of_cosine_similarity.append(sim)\n",
    "\n",
    "    #get the average of the similarities\n",
    "    return sum(list_of_cosine_similarity) / len(list_of_cosine_similarity) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eucliden Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def euclidean_text_distance(text1, text2,vectorizer):\n",
    "    vectors = vectorizer.fit_transform([text1, text2])\n",
    "    return euclidean_distances(vectors)[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(vector1, vector2):\n",
    "    return np.linalg.norm(vector1 - vector2)\n",
    "\n",
    "def run_euclidean_distance(response_df):\n",
    "    euclidean_text_distance_list = []\n",
    "    \n",
    "    # Initialize the vectorizer outside the loop\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    for index, row in response_df.iterrows():\n",
    "        model_response = row['syntheses']\n",
    "        answer = row['answer']\n",
    "        \n",
    "        # Convert the response and answer to a TF-IDF matrix\n",
    "        tfidf_matrix = vectorizer.fit_transform([answer, model_response]).toarray()\n",
    "\n",
    "        # Calculate the Euclidean distance between the vectors\n",
    "        distance = euclidean_distance(tfidf_matrix[0], tfidf_matrix[1])\n",
    "\n",
    "        euclidean_text_distance_list.append(distance)\n",
    "\n",
    "    # Calculate the average Euclidean distance\n",
    "    return sum(euclidean_text_distance_list) / len(euclidean_text_distance_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 10\n",
    "model_ids = [] \n",
    "label_count = [] \n",
    "total_average_cosine_similarities = [] \n",
    "total_average_euclidean_distances = [] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    count += 10\n",
    "    label_count.append(count)\n",
    "    ft_id = fine_tune_model(model_id = 'gpt-3.5-turbo-1106', num_label=count, pandas_df=df)\n",
    "    if wait_for_fine_tuning(ft_id) is not None:\n",
    "        model_ids.append(wait_for_fine_tuning(ft_id))\n",
    "        syntheses_df = generate_10K_responses(data = df, model_id = wait_for_fine_tuning(ft_id))\n",
    "        syntheses_df.to_csv(f'syntheses_df{count}x.csv',index=False)\n",
    "        #total_average_cosine_similarities.append(run_cosine_sim(syntheses_df))\n",
    "        #total_average_euclidean_distances.append(run_euclidean_distance(syntheses_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextClassification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
