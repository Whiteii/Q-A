{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, PyPDFDirectoryLoader, PyPDFLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import openai\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import shutil\n",
    "import os\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_KEY = os.getenv('OPENAI_KEY')\n",
    "openai.api_key = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_stmt_pdf_folder = \"financial_statements\"\n",
    "pdfs = os.listdir(fin_stmt_pdf_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files_path = [fin_stmt_pdf_folder + '\\\\' + pdf_files for pdf_files in pdfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import json\n",
    "import datetime\n",
    "import shutil\n",
    "import openai\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required functions refer to  documentation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_openai_json(data,filename):\n",
    "    \"\"\"\n",
    "    Converts a given dataset into a JSON Lines (JSONL) file suitable for OpenAI's GPT-3.5 turbo model.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame or similar data structure): Input data containing text and labels.\n",
    "\n",
    "    The function processes the input data row by row, constructing conversations for each row with a system message, user message, and an assistant message. It then writes the generated conversation data to a JSONL file.\n",
    " \n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store conversation data\n",
    "    message_list = []\n",
    "\n",
    "    # Iterate through the rows in the input data\n",
    "    for _, row in data.iterrows():\n",
    "        # Create a system message as an initial instruction\n",
    "        system_message = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a factual chatbot that answers questions about 10-K documents. You only answer with answers you find in the text, no outside information.\"\n",
    "        }\n",
    "\n",
    "        # Append the system message to the conversation\n",
    "        message_list.append({\"messages\": [system_message]})\n",
    "\n",
    "        # Create a user message based on the 'text' column from the data\n",
    "        user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": row['question']\n",
    "        }\n",
    "\n",
    "        # Append the user message to the conversation\n",
    "        message_list[-1][\"messages\"].append(user_message)\n",
    "\n",
    "        # Create an assistant message based on the 'coarse_label' column from the data\n",
    "        assistant_message = {\n",
    "            \"role\": 'assistant',\n",
    "            \"content\": row['answer']\n",
    "        }\n",
    "\n",
    "        # Append the assistant message to the conversation\n",
    "        message_list[-1][\"messages\"].append(assistant_message)\n",
    "\n",
    "    # Write the conversation data to a JSON Lines (JSONL) file\n",
    "    with open(filename, \"w\") as json_file:\n",
    "        for message in message_list:\n",
    "            # Serialize the conversation data to JSON and write it to the file\n",
    "            json.dump(message, json_file)\n",
    "            json_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_knowledge_hub(path_to_10k):\n",
    "    \"\"\"From a 10-K document, create a Chroma DB knowledge hub ONLY PDF FILES.\n",
    "\n",
    "    Args:\n",
    "        path_to_10k: Relative path to the 10-K hosted locally on the user's computer\n",
    "\n",
    "    Returns:\n",
    "        vectordb: The vector database with the information from the 10-K\n",
    "        db_directory: The path to the vector database\n",
    "    \"\"\"\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "    timestamp = now.strftime(\"%Y%m%d%H%M%S\")\n",
    "    db_directory = \"db/\" + timestamp\n",
    "\n",
    "    loader = PyPDFLoader(path_to_10k)\n",
    "    documents = loader.load()\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1500, \n",
    "        chunk_overlap=5,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "        length_function=len)\n",
    "    \n",
    "    texts = splitter.split_documents(documents)\n",
    "\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=texts, \n",
    "        embedding=embeddings,\n",
    "        persist_directory=db_directory\n",
    "    )\n",
    "    vectordb.persist()\n",
    "\n",
    "    return vectordb, db_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_chroma_db(db_directory):\n",
    "    \"\"\"Deletes the Chroma DB created locally on the computer\n",
    "\n",
    "    Args:\n",
    "        db_directory: The path to the vector database\n",
    "    \"\"\"\n",
    "    try:\n",
    "        shutil.rmtree(db_directory)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Chroma database '{db_directory}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting Chroma database: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt_nonfinetuned_model(path_to_10k, question):\n",
    "    \"\"\"Ask the original GPT model a question based off a local 10-K document.\n",
    "\n",
    "    Args:\n",
    "        path_to_10k: Relative path to the 10-K hosted locally on the user's computer\n",
    "        question: Question to ask the model\n",
    "\n",
    "    Returns:\n",
    "        answer: The answer given by the GPT model\n",
    "    \"\"\"\n",
    "\n",
    "    db, db_dir = create_knowledge_hub(path_to_10k)\n",
    "\n",
    "    print(db, db_dir)\n",
    "\n",
    "\n",
    "    similarity_search = db.similarity_search(question, k = 5)\n",
    "    source1 = similarity_search[0].page_content\n",
    "    source2 = similarity_search[1].page_content\n",
    "    source3 = similarity_search[2].page_content\n",
    "    source4 = similarity_search[3].page_content\n",
    "    source5 = similarity_search[3].page_content\n",
    "    \n",
    "\n",
    "\n",
    "    #print(source1, source2, source3, source4, source5)\n",
    "\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a factual chatbot that answers questions about 10-K documents. You only answer with answers you find in the text, no outside information.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{source1}{source2}{source3}{source4}{source5} Now, this is our question: {question}\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    \n",
    "    answer = completion.choices[0].message.content\n",
    "\n",
    "    delete_chroma_db(db_dir)\n",
    "\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    financial_statements/0001558370-19-000470.pdf\n",
       "1    financial_statements/0001558370-19-000470.pdf\n",
       "2    financial_statements/0000066740-23-000014.pdf\n",
       "Name: financial_pdf_path, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['financial_pdf_path'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"syntheses = []\\nfor _, row in train_df.iterrows():\\n    path_for_fin_stmt = row['financial_pdf_path']  \\n    question = row['question']\\n    response = ask_gpt_nonfinetuned_model(path_for_fin_stmt, question)\\n\\n    print('question{}'.format(question))\\n\\n    print('response{}' .format(response))\\n\\n    syntheses.append(response)\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntheses = []\n",
    "for _, row in train_df.iterrows():\n",
    "    path_for_fin_stmt = row['financial_pdf_path']  \n",
    "    question = row['question']\n",
    "    response = ask_gpt_nonfinetuned_model(path_for_fin_stmt, question)\n",
    "    print('question{}'.format(question))\n",
    "    print('response{}' .format(response))\n",
    "    syntheses.append(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntheses_df = pd.read_csv('syntheses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_strings(text1, text2):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([text1, text2])\n",
    "    # Calculate the cosine similarity between the vectors\n",
    "    similarity = cosine_similarity(vectors)\n",
    "    return similarity[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('respones_and_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Based on the provided text, 3M's capital spend...</td>\n",
       "      <td>$1577.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The document provided does not include a balan...</td>\n",
       "      <td>$8.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on the FY2022 data, 3M does appear to be...</td>\n",
       "      <td>No, the company is managing its CAPEX and Fixe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The operating income margin for 3M for the yea...</td>\n",
       "      <td>Operating Margin for 3M in FY2022 has decrease...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The text does not provide specific information...</td>\n",
       "      <td>The consumer segment shrunk by 0.9% organically.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>The text states that Verizon's strategy requir...</td>\n",
       "      <td>Yes. Verizon's capital intensity ratio was app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>No, Verizon's balance sheet indicates a decrea...</td>\n",
       "      <td>No. Verizon's debt decreased by $229 million.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>The document does not provide specific informa...</td>\n",
       "      <td>42.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>The unadjusted operating income as a percentag...</td>\n",
       "      <td>0.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>In order to calculate the average unadjusted E...</td>\n",
       "      <td>6.2%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Response  \\\n",
       "0    Based on the provided text, 3M's capital spend...   \n",
       "1    The document provided does not include a balan...   \n",
       "2    Based on the FY2022 data, 3M does appear to be...   \n",
       "3    The operating income margin for 3M for the yea...   \n",
       "4    The text does not provide specific information...   \n",
       "..                                                 ...   \n",
       "145  The text states that Verizon's strategy requir...   \n",
       "146  No, Verizon's balance sheet indicates a decrea...   \n",
       "147  The document does not provide specific informa...   \n",
       "148  The unadjusted operating income as a percentag...   \n",
       "149  In order to calculate the average unadjusted E...   \n",
       "\n",
       "                                                Answer  \n",
       "0                                             $1577.00  \n",
       "1                                                $8.70  \n",
       "2    No, the company is managing its CAPEX and Fixe...  \n",
       "3    Operating Margin for 3M in FY2022 has decrease...  \n",
       "4     The consumer segment shrunk by 0.9% organically.  \n",
       "..                                                 ...  \n",
       "145  Yes. Verizon's capital intensity ratio was app...  \n",
       "146      No. Verizon's debt decreased by $229 million.  \n",
       "147                                              42.69  \n",
       "148                                               0.2%  \n",
       "149                                               6.2%  \n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cosine similarity will evaluate this as 0, which is bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the provided text, 3M's capital spending for 2018 was $1.577 billion.\""
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Response'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$1577.00'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Answer'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compare_strings(text1, text2):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([text1, text2])\n",
    "    # Calculate the cosine similarity between the vectors\n",
    "    similarity = cosine_similarity(vectors)\n",
    "    return similarity[0][1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cosine_sim(path_to_csv_dataset):\n",
    "    list_of_cosine_similarity = []\n",
    "\n",
    "    df = pd.read_csv(path_to_csv_dataset)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        model_response = row['Response']\n",
    "        answer = row['Answer']\n",
    "\n",
    "        #compare similarity\n",
    "        sim = compare_strings(answer, model_response)\n",
    "        #print(\"answers are\", answer, model_response)\n",
    "        #print(\"sim is\", sim)\n",
    "\n",
    "        \n",
    "\n",
    "        #add the similarity to the list\n",
    "        list_of_cosine_similarity.append(sim)\n",
    "\n",
    "    #get the average of the similarities\n",
    "    return sum(list_of_cosine_similarity) / len(list_of_cosine_similarity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total average Euclidean text distance is: 0.1928\n"
     ]
    }
   ],
   "source": [
    "print(f\"The total average Euclidean text distance is: {run_cosine_sim('respones_and_answer.csv'):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def euclidean_text_distance(text1, text2):\n",
    "    \"\"\"Compute the Euclidean distance between two texts.\"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([text1, text2])\n",
    "    return euclidean_distances(vectors)[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_euclidean_distance(path_to_csv_dataset):\n",
    "    euclidean_text_distance_list = []\n",
    "\n",
    "    df = pd.read_csv(path_to_csv_dataset)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        model_response = row['Response']\n",
    "        answer = row['Answer']\n",
    "        \n",
    "        #compare similarity\n",
    "        sim = euclidean_text_distance(answer, model_response)\n",
    "        #print(\"answers are\", answer, model_response)\n",
    "        #print(\"euclidean_text_distance is\", sim)\n",
    "\n",
    "    \n",
    "        #add the similarity to the list\n",
    "        euclidean_text_distance_list.append(sim)\n",
    "\n",
    "    #get the average of the similarities\n",
    "    return sum(euclidean_text_distance_list) / len(euclidean_text_distance_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total average Euclidean text distance is: 1.2295\n"
     ]
    }
   ],
   "source": [
    "    print(f\"The total average Euclidean text distance is: {run_euclidean_distance('respones_and_answer.csv'):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anote_AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
